diff -up onnx-1.18.0/CMakeLists.txt.4~ onnx-1.18.0/CMakeLists.txt
--- onnx-1.18.0/CMakeLists.txt.4~	2025-07-09 01:08:44.171732365 +0200
+++ onnx-1.18.0/CMakeLists.txt	2025-07-09 01:10:23.811068527 +0200
@@ -40,6 +40,7 @@ option(ONNX_USE_LITE_PROTO "Use lite pro
 option(ONNX_DISABLE_EXCEPTIONS "Disable exception handling." OFF)
 option(ONNX_DISABLE_STATIC_REGISTRATION "Disable static registration for ONNX operator schemas." OFF)
 option(ONNX_USE_UNITY_BUILD "Enable Unity (Jumbo) build for" OFF)
+option(ONNX_MINIMAL_BUILD "Build only essential ONNX components" OFF)
 if(WIN32)
   option(ONNX_USE_MSVC_STATIC_RUNTIME "Build with MSVC static runtime" OFF)
 endif()
@@ -461,14 +462,28 @@ relative_protobuf_generate_cpp(gen_onnx_
 list(APPEND ONNX_PROTO_SRCS ${__tmp_srcs})
 list(APPEND ONNX_PROTO_HDRS ${__tmp_hdrs})
 
-file(GLOB_RECURSE __tmp_srcs "${ONNX_ROOT}/onnx/*.h" "${ONNX_ROOT}/onnx/*.cc")
-file(GLOB_RECURSE onnx_gtests_src "${ONNX_ROOT}/onnx/test/cpp/*.h"
-    "${ONNX_ROOT}/onnx/test/cpp/*.cc"
-    "${ONNX_ROOT}/onnx/backend/test/cpp/*.cc"
-    "${ONNX_ROOT}/onnx/backend/test/cpp/*.h")
-list(REMOVE_ITEM __tmp_srcs "${ONNX_ROOT}/onnx/cpp2py_export.cc")
-list(REMOVE_ITEM __tmp_srcs ${onnx_gtests_src})
-list(APPEND ONNX_SRCS ${__tmp_srcs})
+if(ONNX_MINIMAL_BUILD)
+    message(STATUS "Configuring ONNX minimal build")
+    set(ONNX_SRCS
+      "${ONNX_ROOT}/onnx/common/common.h"
+      "${ONNX_ROOT}/onnx/defs/data_type_utils.h"
+      "${ONNX_ROOT}/onnx/defs/data_type_utils.cc"
+    )
+    # Ensure ONNX_ML is treated as ON for minimal build consistency with ORT's file
+    set(ONNX_ML ON CACHE BOOL "Enable traditional ML API." FORCE)
+    # Minimal build doesn't need Python or tests
+    set(ONNX_BUILD_PYTHON OFF CACHE BOOL "Build Python binaries" FORCE)
+    set(ONNX_BUILD_TESTS OFF CACHE BOOL "Build ONNX C++ APIs Tests" FORCE)
+else()
+    file(GLOB_RECURSE __tmp_srcs "${ONNX_ROOT}/onnx/*.h" "${ONNX_ROOT}/onnx/*.cc")
+    file(GLOB_RECURSE onnx_gtests_src "${ONNX_ROOT}/onnx/test/cpp/*.h"
+        "${ONNX_ROOT}/onnx/test/cpp/*.cc"
+        "${ONNX_ROOT}/onnx/backend/test/cpp/*.cc"
+        "${ONNX_ROOT}/onnx/backend/test/cpp/*.h")
+    list(REMOVE_ITEM __tmp_srcs "${ONNX_ROOT}/onnx/cpp2py_export.cc")
+    list(REMOVE_ITEM __tmp_srcs ${onnx_gtests_src})
+    list(APPEND ONNX_SRCS ${__tmp_srcs})
+endif()
 
 add_library(onnx_proto SHARED ${ONNX_PROTO_SRCS} ${ONNX_PROTO_HDRS})
 add_dependencies(onnx_proto gen_onnx_operators_proto gen_onnx_data_proto)
@@ -599,13 +614,6 @@ if(ONNX_BUILD_PYTHON)
     target_link_libraries(onnx_cpp2py_export PRIVATE ${Python3_LIBRARIES})
     target_compile_options(onnx_cpp2py_export
                            PRIVATE /MP
-                                   /wd4146 # unary minus operator applied to unsigned type,
-                                           # result still unsigned
-                                   /wd4244 # 'argument': conversion from 'google::
-                                           # protobuf::uint64' to 'int', possible
-                                           # loss of data
-                                   /wd4267 # Conversion from 'size_t' to 'int',
-                                           # possible loss of data
                                    ${EXTRA_FLAGS})
     add_msvc_runtime_flag(onnx_cpp2py_export)
     add_onnx_global_defines(onnx_cpp2py_export)
@@ -622,23 +630,9 @@ endif()
 if(MSVC)
   target_compile_options(onnx_proto
                          PRIVATE /MP
-                                 /wd4146 # unary minus operator applied to unsigned type,
-                                         # result still unsigned
-                                 /wd4244 #'argument': conversion from 'google::
-                                         #protobuf::uint64' to 'int', possible
-                                         # loss of data
-                                 /wd4267 # Conversion from 'size_t' to 'int',
-                                         # possible loss of data
                                  ${EXTRA_FLAGS})
   target_compile_options(onnx
                          PRIVATE /MP
-                                 /wd4146 # unary minus operator applied to unsigned type,
-                                         # result still unsigned
-                                 /wd4244 # 'argument': conversion from 'google::
-                                         # protobuf::uint64' to 'int', possible
-                                         # loss of data
-                                 /wd4267 # Conversion from 'size_t' to 'int',
-                                         # possible loss of data
                                  ${EXTRA_FLAGS})
   add_msvc_runtime_flag(onnx_proto)
   add_msvc_runtime_flag(onnx)
diff -up onnx-1.18.0/onnx/defs/nn/defs.cc.4~ onnx-1.18.0/onnx/defs/nn/defs.cc
--- onnx-1.18.0/onnx/defs/nn/defs.cc.4~	2025-05-08 19:33:57.000000000 +0200
+++ onnx-1.18.0/onnx/defs/nn/defs.cc	2025-07-09 01:08:44.186860639 +0200
@@ -36,7 +36,7 @@ static const char* conv_transpose_auto_p
     "on whether it is even or odd). In case the padding is an odd number, the extra "
     "padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.";
 
-static void convPoolShapeInference(
+void convPoolShapeInference(
     InferenceContext& ctx,
     bool use_dilation,
     bool require_kernel_shape,
@@ -1102,7 +1102,7 @@ ONNX_OPERATOR_SET_SCHEMA(
           convPoolShapeInference(ctx, true, false, 0, 1);
         }));
 
-static void convTransposeShapeInference(InferenceContext& ctx) {
+void convTransposeShapeInference(InferenceContext& ctx) {
   propagateElemTypeFromInputToOutput(ctx, 0, 0);
 
   // we need at least two inputs to have a shape for this inference.
@@ -1462,7 +1462,7 @@ ONNX_OPERATOR_SET_SCHEMA(
         }));
 
 // For GlobalPool operations.
-static void globalPoolTypeShapeInference(InferenceContext& ctx) {
+void globalPoolTypeShapeInference(InferenceContext& ctx) {
   propagateElemTypeFromInputToOutput(ctx, 0, 0);
 
   // needs at least one input with shape.
diff -up onnx-1.18.0/onnx/defs/nn/old.cc.4~ onnx-1.18.0/onnx/defs/nn/old.cc
--- onnx-1.18.0/onnx/defs/nn/old.cc.4~	2025-05-08 19:33:57.000000000 +0200
+++ onnx-1.18.0/onnx/defs/nn/old.cc	2025-07-09 01:08:44.187162268 +0200
@@ -4023,7 +4023,6 @@ ONNX_OPERATOR_SET_SCHEMA(
     GroupNormalization,
     18,
     OpSchema()
-        .Deprecate()
         .SetDoc(GroupNormalization_ver18_doc)
         .Attr("epsilon", "The epsilon value to use to avoid division by zero.", AttributeProto::FLOAT, 1e-5f)
         .Attr(
diff -up onnx-1.18.0/onnx/defs/rnn/defs.cc.4~ onnx-1.18.0/onnx/defs/rnn/defs.cc
--- onnx-1.18.0/onnx/defs/rnn/defs.cc.4~	2025-05-08 19:33:57.000000000 +0200
+++ onnx-1.18.0/onnx/defs/rnn/defs.cc	2025-07-09 01:08:44.187310517 +0200
@@ -5,7 +5,7 @@
 #include "onnx/defs/schema.h"
 
 namespace ONNX_NAMESPACE {
-static void RNNShapeInference(InferenceContext& ctx) {
+void RNNShapeInference(InferenceContext& ctx) {
   TensorShapeProto::Dimension num_directions, seq_length, batch_size, hidden_size;
 
   auto direction = getAttribute(ctx, "direction", "forward");
diff -up onnx-1.18.0/onnx/defs/schema.h.4~ onnx-1.18.0/onnx/defs/schema.h
--- onnx-1.18.0/onnx/defs/schema.h.4~	2025-05-08 19:33:57.000000000 +0200
+++ onnx-1.18.0/onnx/defs/schema.h	2025-07-09 01:08:44.187380850 +0200
@@ -980,10 +980,7 @@ class OpSchemaRegistry final : public IS
   class OpSchemaRegisterOnce final {
    public:
     // Export to cpp custom register macro
-    explicit OpSchemaRegisterOnce(
-        OpSchema op_schema,
-        int opset_version_to_load = 0,
-        bool fail_duplicate_schema = true) {
+    OpSchemaRegisterOnce(OpSchema op_schema, int opset_version_to_load = 0, bool fail_duplicate_schema = true) {
       OpSchemaRegisterNoExcept(std::move(op_schema), opset_version_to_load, fail_duplicate_schema);
     }
     static void
